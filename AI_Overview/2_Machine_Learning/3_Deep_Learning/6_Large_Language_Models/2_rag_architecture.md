# RAG Architecture 檢索增強生成

如果微調是讓 AI **死背書**，那麼 RAG **Retrieval-Augmented Generation** 就是讓 AI **開卷考**。

核心概念是 **外掛知識庫 External Knowledge Base**：
> 不要強迫 AI 把所有知識記在腦子裡，而是教它在回答問題前，先去翻閱百科全書或公司手冊。

## 為什麼需要 RAG？

LLM 有三個致命傷，而 RAG 是最佳解藥：
1.  **一本正經胡說八道 Hallucinations:** AI 不懂也會裝懂。
    - **RAG:** 強制 AI 只能根據檢索到的資料回答，有憑有據。
2.  **知識過期 Knowledge Cutoff:** GPT-4 訓練資料只到 2023 年。
    - **RAG:** 只要更新外部資料庫，AI 就能讀到今天的頭條新聞。
3.  **私有資料 Private Data:** 企業內部的機密文件不可能拿給 OpenAI 訓練。
    - **RAG:** 資料庫建在本地，AI 只是幫忙閱讀和總結，資料不需外流。

## 運作流程

這個過程分為三個步驟：

### 1. 檢索 Retrieve
當使用者問：「公司的請假規定是什麼？」
系統會先把這個問題變成向量，去公司的文件庫中搜尋最相關的段落 例如人事規章第 5 條。

### 2. 增強 Augment
系統會把 **問題** 和 **搜到的答案** 一起打包成一個新的提示詞 Prompt：
> "請根據以下資料：『人事規章第 5 條：員工每年有 7 天特休...』
> 回答使用者的問題：『公司的請假規定是什麼？』"

### 3. 生成 Generate
LLM 閱讀這段完整的提示詞，然後生成最終答案給使用者。
AI 其實不是在回答問題，而是在做 **閱讀測驗**。

## RAG vs Fine-tuning

| 特性     | 微調 Fine-tuning                    | RAG                                 |
| :------- | :---------------------------------- | :---------------------------------- |
| **類比** | **考前衝刺** 把課本背下來           | **開卷考試** 帶著課本進考場         |
| **適用** | 改變 AI 的 **說話風格** 或 **格式** | 增加 AI 的 **新知識** 或 **準確度** |
| **成本** | 高 (需要 GPU 訓練)                  | 低 (只需要資料庫)                   |
| **更新** | 慢 (要重新訓練)                     | 快 (直接換掉文件即可)               |

## 結論

在企業落地應用中，**RAG** 遠比微調更重要。它解決了 AI 的信任問題，讓大型語言模型真正成為可用的生產力工具。
