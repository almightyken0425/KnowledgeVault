# Pre-training and Fine-tuning 預訓練與微調

這是打造一個 ChatGPT 等級 AI 的必經之路。如果把 AI 比喻成一個學生，這就是它的 **大學教育** 與 **職前訓練**。

## 預訓練 Pre-training 通識教育
**目標:** 讓模型學會 **理解人類語言** 與 **具備世界知識**。

- **資料:** 網際網路上數以兆計的文字。包含維基百科、書籍、程式碼、Reddit 論壇討論。
- **任務:** **預測下一個字 Next Token Prediction**。
    - 給定: "床前明月光"
    - 預測: "疑"
    - 只要預測錯誤就處罰，預測正確就獎勵。
- **成本:** 極度昂貴。需要數千張 GPU 跑好幾個月。
- **結果:** 得到一個 **Base Model 基底模型**。它懂天文地理，會寫程式，但它不知道怎麼跟你對話。你問它問題，它可能會反問你更多問題，因為它以為它在補全網頁上的問答集。

## 微調 Fine-tuning 職前訓練
**目標:** 讓模型學會 **聽從指令** 與 **符合人類價值觀**。

這通常包含兩個階段：

### 指令微調 Instruction Tuning
- **資料:** 人類精心撰寫的問答對 Q&A Pairs。
- **任務:** 學習對話模式。
    - User: "請幫我寫一首詩。"
    - AI: "好的，這是一首關於春天的詩..."
- **結果:** 模型由 "續寫機器" 變成了 "對話機器"。

### 人類回饋強化學習 RLHF
- **資料:** 人類對 AI 回答的評分與排名。
- **任務:** 學習什麼是好的回答。不僅要正確，還要無害、有禮貌、不帶偏見。
- **結果:** 得到一個 **Chat Model 對話模型**。這就是我們現在使用的 ChatGPT。

## 結論

- **預訓練:** 決定了模型的 **知識廣度** 與 **智力上限**。
- **微調:** 決定了模型的 **性格**、**用途** 與 **安全性**。

企業通常不需要重新做預訓練，只需要拿開源的 Base Model，例如 LLaMA，進行微調，就能擁有自己的專屬 AI。
