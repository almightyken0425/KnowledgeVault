# YOLO Spec: You Only Look Once

這是現代物件偵測 **Object Detection** 的里程碑。它的名字 **You Only Look Once** 完美詮釋了它的核心精神：快。

核心概念是 **單次掃描 Single Shot**：
> 不要像傳統方法那樣先產生幾千個候選框再慢慢篩選，而是直接把整張圖片丟進神經網路，一次吐出所有物件的位置與類別。

## 核心機制 The Grid System

YOLO 將輸入圖片切割成 $S \times S$ 的網格。
例如 7x7 的網格。

### 責任歸屬
如果一個物件的 **中心點** 落在哪個網格內，那個網格就負責偵測這個物件。

### 每個網格的輸出
每個網格需要預測 $B$ 個邊界框 Bounding Boxes 以及 $C$ 個類別機率。
輸出向量包含：
- **位置:** x, y, w, h 代表方框的中心與長寬。
- **信心度:** Confidence Score 代表盒子裡有東西的機率 * IoU。
- **類別:** Class Probabilities 代表它是貓、狗還是車。

## 損失函數 Loss Function

YOLO 的訓練目標是最小化三種誤差的總和：
- **位置誤差:** 預測框跟真實框的位置差多遠？座標 x, y 誤差。
- **尺寸誤差:** 預測框的大小對不對？長寬 w, h 誤差。
- **分類誤差:** 這是貓還是狗？類別誤差。

## 與 R-CNN 的比較

| 特性     | Two-Stage R-CNN 系列 | One-Stage YOLO 系列 |
| :------- | :--------------------------------------------- | :-------------------------------------- |
| **流程** | **兩階段** 先找候選區 Region Proposal 再做分類 | **一階段** 直接回歸預測座標與類別       |
| **速度** | **慢** 每秒約 5 張 FPS                         | **極快** 每秒可達 45+ 張 FPS 即時運算   |
| **精度** | **高** 對小物件偵測較準                        | **略低** 早期版本對重疊物件和小物件較弱 |
| **應用** | 醫療影像分析、精密檢測                         | 自駕車、監視器畫面、手機應用            |

## 演進歷程

- **YOLO v1:** 2015 年橫空出世，證明了 Real-Time Detection 是可能的。
- **YOLO v3:** 引入 FPN 特徵金字塔，大幅改善小物件偵測能力。
- **YOLO v5 / v8:** 現代工業界標準，極度輕量化且易於部署 python 簡單好用。

## 總結

YOLO 將物件偵測問題從 **分類問題 Classification** 轉化為 **回歸問題 Regression**。它不追求看得很仔細，但追求看一眼就知道大概在哪裡。
