# Pooling Layer 池化層

如果卷積層是在 **發現特徵**，那麼池化層就是在 **精簡特徵**。這是一道非常有效的降維手續，能讓模型更輕量且更具強健性。

核心概念是 **降維取樣 Downsampling**：
> 將圖片縮小，保留最重要的資訊，丟棄不重要的細節。

## 運作原理

池化層同樣使用一個滑動視窗通常是 2x2，但它不進行加權運算，而是直接執行簡單的統計操作。

### 最大池化 Max Pooling 最常用
只保留視窗內 **最大** 的數值。
- **邏輯:** 如果這個區域內有偵測到特徵 例如眼睛，那麼這個特徵強度數值會很大。我們只關心 **有沒有** 眼睛，而不關心眼睛精確在左邊一點還是右邊一點。
- **效果:** 能夠提取最顯著的特徵。

### 平均池化 Average Pooling
保留視窗內所有數值的 **平均值**。
- **邏輯:** 保留整體的平均強度，讓圖像變得模糊平滑。
- **效果:** 保留背景資訊，但可能會稀釋掉顯著特徵。

## 為什麼需要池化？

### 減少運算量
將 2x2 的區域縮成 1 個像素，資料量直接減少 75%。這讓後續的全連接層參數大幅減少，避免過擬合。

### 平移不變性 Translation Invariance
這是池化層最強大的特性。
- **情境:** 貓的照片往右移了 3 個像素。
- **原本:** 像素數值完全改變，傳統電腦認為是兩張不同的圖。
- **池化後:** 因為是取區域最大值，只要貓還在這個區域內，Max Pooling 的輸出結果是 **一樣的**。
- **結論:** 模型學會了 **貓就是貓**，不管牠在圖片的左邊還是右邊。

## 缺點與現代趨勢

雖然池化層非常有效，但它畢竟丟失了大量資訊 例如精確的位置資訊。
在最新的神經網路架構中 如 ResNet，有時會傾向使用 **步幅 Stride > 1** 的卷積層來代替池化層進行降維，這樣可以讓神經網路自己學習如何最佳化地縮小圖片，而不是強制取最大值。
